{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "from array import array\n",
    "from os import path\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#скачание датасета\n",
    "\n",
    "# train_dataset = torchvision.datasets.MNIST(root=\"c:/users/abobantai/Desktop/IT/pytorchl\", train=True, download=True)\n",
    "# test_dataset = torchvision.datasets.MNIST(root=\"c:/users/abobantai/Desktop/IT/pytorchl\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#распаковка датасета\n",
    "\n",
    "# def read(dataset):\n",
    "#     if dataset is \"training\":\n",
    "#         path_img = \"c:/users/abobantai/Desktop/IT/pytorchl/MNIST/raw/train-images-idx3-ubyte\"\n",
    "#         path_lbl = \"c:/users/abobantai/Desktop/IT/pytorchl/MNIST/raw/train-labels-idx1-ubyte\"\n",
    "#     elif dataset is \"testing\":\n",
    "#         path_img = \"c:/users/abobantai/Desktop/IT/pytorchl/MNIST/raw/t10k-images-idx3-ubyte\"\n",
    "#         path_lbl = \"c:/users/abobantai/Desktop/IT/pytorchl/MNIST/raw/t10k-labels-idx1-ubyte\"\n",
    "#     else:\n",
    "#         raise ValueError(\"dataset must be \\\"training\\\" or \\\"testing\\\"\")\n",
    "#     with open(path_lbl, \"rb\") as f_label:\n",
    "#         _, size = struct.unpack(\">II\", f_label.read(8))\n",
    "#         lbl = array(\"b\", f_label.read())\n",
    "#     with open(path_img, \"rb\") as f_img:\n",
    "#         _, size, rows, cols = struct.unpack(\">IIII\", f_img.read(16))\n",
    "#         img = array(\"b\", f_img.read())\n",
    "#     return lbl, img, size, rows, cols\n",
    "# def write_dataset(labels, data, size, rows, cols, output_dir):\n",
    "#     classes = {i :f\"class{i}\" for i in range(10)}\n",
    "#     output_dirs = [\n",
    "#         path.join(output_dir, classes[i])\n",
    "#         for i in range(10)\n",
    "#     ]\n",
    "#     for dir in output_dirs:\n",
    "#         if not path.exists(dir):\n",
    "#             os.makedirs(dir)\n",
    "#     for (i, label) in enumerate(labels):\n",
    "#         output_filename = path.join(output_dirs[label], str(i) + \".png\")\n",
    "#         print(\"writing \" + output_filename)\n",
    "#         with open(output_filename, \"wb\") as h:\n",
    "#             data_i = [\n",
    "#                 data[ (i*rows*cols + j*cols) : (i*rows*cols + (j+1)*cols) ]\n",
    "#                 for j in range(rows)\n",
    "#             ]\n",
    "#             data_array = np.asarray(data_i)\n",
    "#             im = Image.fromarray(data_array)\n",
    "#             im.save(output_filename)\n",
    "# output_path = \"c:/users/abobantai/Desktop/IT/pytorchl/mnist\"\n",
    "# for dataset in [\"training\", \"testing\"]:\n",
    "#     write_dataset(*read(dataset), path.join(output_path, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# определение процессора для обучения\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abobantai\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#все необходимые трансформаций для MNIST\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.ToTensor(),\n",
    "    v2.Grayscale(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=([0.5]), std=([0.5]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = ImageFolder(root=\"mnist/training\",transform=transforms)\n",
    "test_data = ImageFolder(root=\"mnist/testing\",transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = random_split(train_data, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_data = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_data = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание модели с помощью nn.Sequential()\n",
    "\n",
    "\n",
    "# model = nn.Sequential(\n",
    "#     nn.Linear(784,198),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(196,49),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(49,10),\n",
    "#     nn.Softmax()\n",
    "# ).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание модели с помощью nn.Sequential(), и добавление слои с именами\n",
    "\n",
    "\n",
    "# model = nn.Sequential()\n",
    "# model.add_module('lineat_layer1', nn.Linear(784, 392))\n",
    "# model.add_module('relu1', nn.ReLU())\n",
    "# model.add_module('linear_layer2', nn.Linear(392, 98))\n",
    "# model.add_module('sigmoid2', nn.Sigmoid())\n",
    "# model.add_module('linear_layer3', nn.Linear(98, 10))\n",
    "# model.add_module('softmax3', nn.Softmax())\n",
    "# model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание модели с помощью класса nn.Module\n",
    "\n",
    "class myModel(nn.Module):\n",
    "    def __init__(self, input, output): # определение класа\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input, 512) # первый слои вход=784 выход=512\n",
    "        self.layer2 = nn.Linear(512, 128)# второй слои вход=512 выход=128\n",
    "        self.layer3 = nn.Linear(128, output)# второй слои вход=128 выход=10\n",
    "        self.relu = nn.ReLU() # функция активация relu\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x) # подача данных в первый слои и запись выхода в переменную х\n",
    "        x = self.layer2(x) # подача данных с первого слоя на в второй слои и запись выхода в переменную х\n",
    "        x = self.relu(x) # подача данных со второгого слоя на функция активация и запись выхода в переменную х\n",
    "        x = self.layer3(x)\n",
    "        return x # возврацение вычислений модели\n",
    "model = myModel(784, 10).to(device) # определение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-архиектура:\n",
    "\n",
    "**гиперпараметры:**\n",
    "|ТИП|ЗНАЧЕНИЕ|\n",
    "|-|-|\n",
    "|эпохи|120|\n",
    "|оптимизатор|adam|\n",
    "|вычисление ошибки|CrossEntropyLoss|\n",
    "|батчи|64|\n",
    "\n",
    "\n",
    "**предельная возможность**\n",
    "|ТИП|ЗНАЧЕНИЕ|\n",
    "|-|-|\n",
    "|train_loss:         |0.0078            |\n",
    "|train_acc:          |0.9975            |\n",
    "|val_loss:           |0.0136            |\n",
    "|val_acc:            |0.9946            |\n",
    "|test_loss:           |0.0740            |\n",
    "|test_acc:            |0.9766            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# настроика оптимизатора, вычисления ошибки и шедулера\u001b[39;00m\n\u001b[0;32m      3\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m----> 4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m      5\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optimizer, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "# настроика оптимизатора, вычисления ошибки и шедулера\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создания списка для анализа обучения модели\n",
    "\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "lr_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#цикл обучения модели\n",
    "\n",
    "epochs = 120 #эпохи\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_loop = tqdm(train_data, leave=False)  # определение прогрес бара\n",
    "    true_answer = 0 # счет правильных ответов за каждую эпоху не включая данных валидаций\n",
    "    runnig_train_loss = [] # список ошибок тренировки каждой эпохи\n",
    "    model.train()\n",
    "    for x, tpred in train_loop: # перебор всех батчей тренировочных данных\n",
    "        x = x.reshape(-1, 28*28).to(device) # преоброзавание данных для модели\n",
    "        tpred = tpred.reshape(-1).to(torch.int32) # преоброзавание данных для модели\n",
    "        tpred = torch.eye(10)[tpred].to(device) # преоброзавание правильных ответов на ванхотвектора\n",
    "\n",
    "        pred = model(x) # подача изображения в модель\n",
    "        los = loss(pred, tpred) # вычисление ошибки\n",
    "\n",
    "        optimizer.zero_grad() # обнуление градиентов \n",
    "        los.backward() # обратное распростронение\n",
    "        optimizer.step() # обновление\n",
    "\n",
    "        runnig_train_loss.append(los.item()) # добавление значений ошибок в список\n",
    "        mean_train_loss = sum(runnig_train_loss) / len(runnig_train_loss) # вычисление среднего значения ошибок\n",
    "\n",
    "        true_answer += (pred.argmax(dim=1) == tpred.argmax(dim=1)).sum().item() # счетчик правильных предсказаний\n",
    "\n",
    "        train_loop.set_description(f\"epoch [{epoch+1}], train_loss = {mean_train_loss:.4f}\") \n",
    "    runnig_train_acc = true_answer/64 / len(train_data) # вычисление точность предсказаний модели\n",
    "\n",
    "    train_loss.append(mean_train_loss) # добавления среднего значения ошибок модели в список для анализа\n",
    "    train_acc.append(runnig_train_acc) # добавления среднего значения точности предсказаний моделя в список для анализа\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad(): # режим отключения вычисления градиентов\n",
    "        runnig_val_loss = [] # список ошибок моделя в валидаций\n",
    "        true_answer = 0 # счет правильных ответов в валидаций\n",
    "        for x, tpred in val_data:\n",
    "            x = x.reshape(-1, 28*28).to(device)\n",
    "            tpred = tpred.reshape(-1).to(torch.int32)\n",
    "            tpred = torch.eye(10)[tpred].to(device)\n",
    "\n",
    "            pred = model(x)\n",
    "            los = loss(pred, tpred)\n",
    "\n",
    "            runnig_val_loss.append(los.item()) \n",
    "            mean_val_loss = sum(runnig_val_loss) / len(runnig_val_loss)\n",
    "            true_answer += (pred.argmax(dim=1) == tpred.argmax(dim=1)).sum().item()\n",
    "        runnig_val_acc = true_answer/64 / len(val_data)\n",
    "        val_loss.append(mean_val_loss)\n",
    "        val_acc.append(runnig_val_acc)\n",
    "    #                                       |\n",
    "    # вывод результата обучения одной эпохи\\|/\n",
    "    #                                       '\n",
    "    print(f\"epoch [{epoch+1}/{epochs}], train_loss = {mean_train_loss:.4f}, train_acc = {runnig_train_acc:.4f}, val_loss = {mean_val_loss:.4f}, val_acc = {runnig_val_acc:.4f}, lr = {lr}\")\n",
    "    scheduler.step(mean_val_loss) #обновление шедулера\n",
    "    lr = scheduler._last_lr[0] # текущяя скорость обучения\n",
    "    lr_list.append(lr) # добавления значения скорости обучения в список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#график ошибки моделя при тренировки и валидаций\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['train_loss','val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#график точности моделя при тренировке и валидаций\n",
    "\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.legend(['train_acc','val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#график изменений скорости обучения\n",
    "\n",
    "plt.plot(lr_list)\n",
    "plt.legend(['lr'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#сохранение модели\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#для каждой архитектуры бдует создана новый каталог в каталоге models\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msave(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/model1/model1.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#сохранение модели\n",
    "#\n",
    "#для каждой архитектуры бдует создана новый каталог в каталоге models\n",
    "\n",
    "torch.save(model, 'models/model1/model1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abobantai\\AppData\\Local\\Temp\\ipykernel_18040\\3841130397.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dict = torch.load('models/model1/model1.pt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = torch.load('models/model1/model1.pt')\n",
    "model.load_state_dict(model_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9766122611464968\n",
      "0.07405926361444895\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # режим отключения вычисления градиентов\n",
    "        runnig_test_loss = [] # список ошибок моделя в тесте\n",
    "        true_answer = 0 # счет правильных предсказаний в тесте\n",
    "        for x, tpred in test_data:\n",
    "            x = x.reshape(-1, 28*28).to(device)\n",
    "            tpred = tpred.reshape(-1).to(torch.int32)\n",
    "            tpred = torch.eye(10)[tpred].to(device)\n",
    "\n",
    "            pred = model(x)\n",
    "            los = loss(pred, tpred)\n",
    "\n",
    "            runnig_test_loss.append(los.item()) \n",
    "            mean_test_loss = sum(runnig_test_loss) / len(runnig_test_loss)\n",
    "            true_answer += (pred.argmax(dim=1) == tpred.argmax(dim=1)).sum().item()\n",
    "        runnig_test_acc = true_answer/64 / len(test_data)\n",
    "print(runnig_test_acc)\n",
    "print(mean_test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
