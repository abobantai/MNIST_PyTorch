{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "from array import array\n",
    "from os import path\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#скачание датасета\n",
    "\n",
    "# train_dataset = torchvision.datasets.MNIST(root=\"c:/users/abobantai/Desktop/IT/pytorchl\", train=True, download=True)\n",
    "# test_dataset = torchvision.datasets.MNIST(root=\"c:/users/abobantai/Desktop/IT/pytorchl\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#распаковка датасета\n",
    "\n",
    "# def read(dataset):\n",
    "#     if dataset is \"training\":\n",
    "#         path_img = \"c:/users/abobantai/Desktop/IT/pytorchl/MNIST/raw/train-images-idx3-ubyte\"\n",
    "#         path_lbl = \"c:/users/abobantai/Desktop/IT/pytorchl/MNIST/raw/train-labels-idx1-ubyte\"\n",
    "#     elif dataset is \"testing\":\n",
    "#         path_img = \"c:/users/abobantai/Desktop/IT/pytorchl/MNIST/raw/t10k-images-idx3-ubyte\"\n",
    "#         path_lbl = \"c:/users/abobantai/Desktop/IT/pytorchl/MNIST/raw/t10k-labels-idx1-ubyte\"\n",
    "#     else:\n",
    "#         raise ValueError(\"dataset must be \\\"training\\\" or \\\"testing\\\"\")\n",
    "#     with open(path_lbl, \"rb\") as f_label:\n",
    "#         _, size = struct.unpack(\">II\", f_label.read(8))\n",
    "#         lbl = array(\"b\", f_label.read())\n",
    "#     with open(path_img, \"rb\") as f_img:\n",
    "#         _, size, rows, cols = struct.unpack(\">IIII\", f_img.read(16))\n",
    "#         img = array(\"b\", f_img.read())\n",
    "#     return lbl, img, size, rows, cols\n",
    "# def write_dataset(labels, data, size, rows, cols, output_dir):\n",
    "#     classes = {i :f\"class{i}\" for i in range(10)}\n",
    "#     output_dirs = [\n",
    "#         path.join(output_dir, classes[i])\n",
    "#         for i in range(10)\n",
    "#     ]\n",
    "#     for dir in output_dirs:\n",
    "#         if not path.exists(dir):\n",
    "#             os.makedirs(dir)\n",
    "#     for (i, label) in enumerate(labels):\n",
    "#         output_filename = path.join(output_dirs[label], str(i) + \".png\")\n",
    "#         print(\"writing \" + output_filename)\n",
    "#         with open(output_filename, \"wb\") as h:\n",
    "#             data_i = [\n",
    "#                 data[ (i*rows*cols + j*cols) : (i*rows*cols + (j+1)*cols) ]\n",
    "#                 for j in range(rows)\n",
    "#             ]\n",
    "#             data_array = np.asarray(data_i)\n",
    "#             im = Image.fromarray(data_array)\n",
    "#             im.save(output_filename)\n",
    "# output_path = \"c:/users/abobantai/Desktop/IT/pytorchl/mnist\"\n",
    "# for dataset in [\"training\", \"testing\"]:\n",
    "#     write_dataset(*read(dataset), path.join(output_path, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определение процессора для обучения\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#все необходимые трансформаций для MNIST\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.ToTensor(),\n",
    "    v2.Grayscale(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=([0.5]), std=([0.5]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = ImageFolder(root=\"mnist/training\",transform=transforms)\n",
    "test_data = ImageFolder(root=\"mnist/testing\",transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = random_split(train_data, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_data = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_data = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание модели с помощью nn.Sequential()\n",
    "\n",
    "\n",
    "# model = nn.Sequential(\n",
    "#     nn.Linear(784,198),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(196,49),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(49,10),\n",
    "#     nn.Softmax()\n",
    "# ).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание модели с помощью nn.Sequential(), и добавление слои с именами\n",
    "\n",
    "\n",
    "# model = nn.Sequential()\n",
    "# model.add_module('lineat_layer1', nn.Linear(784, 392))\n",
    "# model.add_module('relu1', nn.ReLU())\n",
    "# model.add_module('linear_layer2', nn.Linear(392, 98))\n",
    "# model.add_module('sigmoid2', nn.Sigmoid())\n",
    "# model.add_module('linear_layer3', nn.Linear(98, 10))\n",
    "# model.add_module('softmax3', nn.Softmax())\n",
    "# model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание модели с помощью класса nn.Module\n",
    "\n",
    "class myModel(nn.Module):\n",
    "    def __init__(self, input, output): # определение класа\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input, 128) # первый слои вход=784 выход=128\n",
    "        self.layer2 = nn.Linear(128, output)# второй слои вход=128 выход=10\n",
    "        self.relu = nn.ReLU() # функция активация relu\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x) # подача данных в первый слои и запись выхода в переменную х\n",
    "        x = self.layer2(x) # подача данных с первого слоя на в второй слои и запись выхода в переменную х\n",
    "        x = self.relu(x) # подача данных со второгого слоя на функция активация и запись выхода в переменную х\n",
    "        return x # возврацение вычислений модели\n",
    "model = myModel(784, 10).to(device) # определение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-архиектура:\n",
    "\n",
    "**гиперпараметры:**\n",
    "|ТИП|ЗНАЧЕНИЕ|\n",
    "|-|-|\n",
    "|эпохи|120|\n",
    "|оптимизатор|adam|\n",
    "|вычисление ошибки|CrossEntropyLoss|\n",
    "|батчи|64|\n",
    "\n",
    "\n",
    "**предельная возможность**\n",
    "|ТИП|ЗНАЧЕНИЕ|\n",
    "|-|-|\n",
    "|train_loss:         |0.2168            |\n",
    "|train_acc:          |0.9383            |\n",
    "|val_loss:           |0.2753            |\n",
    "|val_acc:            |0.9186            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# настроика оптимизатора, вычисления ошибки и шедулера\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создания списка для анализа обучения модели\n",
    "\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "lr_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#цикл обучения модели\n",
    "\n",
    "epochs = 60 #эпохи\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_loop = tqdm(train_data, leave=False)  # определение прогрес бара\n",
    "    true_answer = 0 # счет правильных ответов за каждую эпоху не включая данных валидаций\n",
    "    runnig_train_loss = [] # список ошибок тренировки каждой эпохи\n",
    "    model.train()\n",
    "    for x, tpred in train_loop: # перебор всех батчей тренировочных данных\n",
    "        x = x.reshape(-1, 28*28).to(device) # преоброзавание данных для модели\n",
    "        tpred = tpred.reshape(-1).to(torch.int32) # преоброзавание данных для модели\n",
    "        tpred = torch.eye(10)[tpred].to(device) # преоброзавание правильных ответов на ванхотвектора\n",
    "\n",
    "        pred = model(x) # подача изображения в модель\n",
    "        los = loss(pred, tpred) # вычисление ошибки\n",
    "\n",
    "        optimizer.zero_grad() # обнуление градиентов \n",
    "        los.backward() # обратное распростронение\n",
    "        optimizer.step() # обновление\n",
    "\n",
    "        runnig_train_loss.append(los.item()) # добавление значений ошибок в список\n",
    "        mean_train_loss = sum(runnig_train_loss) / len(runnig_train_loss) # вычисление среднего значения ошибок\n",
    "\n",
    "        true_answer += (pred.argmax(dim=1) == tpred.argmax(dim=1)).sum().item() # счетчик правильных предсказаний\n",
    "\n",
    "        train_loop.set_description(f\"epoch [{epoch+1}], train_loss = {mean_train_loss:.4f}\") \n",
    "    runnig_train_acc = true_answer/64 / len(train_data) # вычисление точность предсказаний модели\n",
    "\n",
    "    train_loss.append(mean_train_loss) # добавления среднего значения ошибок модели в список для анализа\n",
    "    train_acc.append(runnig_train_acc) # добавления среднего значения точности предсказаний моделя в список для анализа\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad(): # режим отключения вычисления градиентов\n",
    "        runnig_val_loss = [] # список ошибок моделя в валидаций\n",
    "        true_answer = 0 # счет правильных ответов в валидаций\n",
    "        for x, tpred in val_data:\n",
    "            x = x.reshape(-1, 28*28).to(device)\n",
    "            tpred = tpred.reshape(-1).to(torch.int32)\n",
    "            tpred = torch.eye(10)[tpred].to(device)\n",
    "\n",
    "            pred = model(x)\n",
    "            los = loss(pred, tpred)\n",
    "\n",
    "            runnig_val_loss.append(los.item()) \n",
    "            mean_val_loss = sum(runnig_val_loss) / len(runnig_val_loss)\n",
    "            true_answer += (pred.argmax(dim=1) == tpred.argmax(dim=1)).sum().item()\n",
    "        runnig_val_acc = true_answer/64 / len(val_data)\n",
    "        val_loss.append(mean_val_loss)\n",
    "        val_acc.append(runnig_val_acc)\n",
    "    #                                       |\n",
    "    # вывод результата обучения одной эпохи\\|/\n",
    "    #                                       '\n",
    "    print(f\"epoch [{epoch+1}/{epochs}], train_loss = {mean_train_loss:.4f}, train_acc = {runnig_train_acc:.4f}, val_loss = {mean_val_loss:.4f}, val_acc = {runnig_val_acc:.4f}, lr = {lr}\")\n",
    "    scheduler.step(mean_val_loss) #обновление шедулера\n",
    "    lr = scheduler._last_lr[0] # текущяя скорость обучения\n",
    "    lr_list.append(lr) # добавления значения скорости обучения в список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#график ошибки моделя при тренировки и валидаций\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['train_loss','val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#график точности моделя при тренировке и валидаций\n",
    "\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.legend(['train_acc','val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#график изменений скорости обучения\n",
    "\n",
    "plt.plot(lr_list)\n",
    "plt.legend(['lr'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохранение модели\n",
    "#\n",
    "#для каждой архитектуры бдует создана новый каталог в каталоге models\n",
    "\n",
    "torch.save(model, 'models/model1/model1.m5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
